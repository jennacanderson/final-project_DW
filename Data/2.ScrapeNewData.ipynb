{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ad2a8d-8d9e-40e4-b3cb-709f2960a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By # used to import different ways to access data in the XML or HTML file\n",
    "from selenium.webdriver.chrome.service import Service # no longer need to download a driver file, use service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager # used to manage the Chrome driver to emulate a Chrome web browser\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbe990-4266-42ef-82d0-38e3dd2ab9c2",
   "metadata": {},
   "source": [
    "## Scrape the University of Iowa Crime Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dc773c-ca62-4d1a-a03a-7318ccedc062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Case Number                                     Classification  \\\n",
      "0    CRM-2025-415                              Liquor Law Violations   \n",
      "1    CRM-2025-413                                     Simple Assault   \n",
      "2    CRM-2025-410                                  Simple Assault x3   \n",
      "3    CRM-2025-412                                  Criminal Mischief   \n",
      "4    CRM-2025-406  Disorderly - Public Urination, Liquor Law Viol...   \n",
      "..            ...                                                ...   \n",
      "129  CRM-2025-296                                     Simple Assault   \n",
      "130  CRM-2025-294                                     Simple Assault   \n",
      "131  CSA-2025-199                                         Harassment   \n",
      "132  CRM-2025-291                                              Theft   \n",
      "133  CRM-2025-292                                  Criminal Mischief   \n",
      "\n",
      "                                Date/Time Occurred Date/Time Reported  \\\n",
      "0                                 05/07/2025 01:44   05/07/2025 01:44   \n",
      "1                                 05/06/2025 12:51   05/06/2025 12:51   \n",
      "2                                 05/05/2025 18:41   05/05/2025 18:41   \n",
      "3    Between 05/05/2025 00:00 and 05/06/2025 07:12   05/06/2025 07:12   \n",
      "4                                 05/04/2025 01:07   05/04/2025 01:07   \n",
      "..                                             ...                ...   \n",
      "129  Between 04/02/2025 17:24 and 04/02/2025 17:35   04/02/2025 17:49   \n",
      "130                               04/02/2025 07:18   04/02/2025 07:18   \n",
      "131                               04/01/2025 18:59   04/01/2025 18:59   \n",
      "132  Between 04/01/2025 11:13 and 04/01/2025 12:14   04/01/2025 12:33   \n",
      "133  Between 04/01/2025 08:00 and 04/01/2025 14:32   04/01/2025 14:59   \n",
      "\n",
      "                                        Location  \\\n",
      "0                                    Slater Hall   \n",
      "1         UI Health Care Medical Center Downtown   \n",
      "2    UI Health Care Medical Center North Liberty   \n",
      "3          President's Residence, retaining wall   \n",
      "4                                     Pentacrest   \n",
      "..                                           ...   \n",
      "129                             General Hospital   \n",
      "130       UI Health Care Medical Center Downtown   \n",
      "131                      Petersen Residence Hall   \n",
      "132        Campus Recreation and Wellness Center   \n",
      "133                                 Hubbard Park   \n",
      "\n",
      "                                           Disposition  \n",
      "0    Closed - Referred to Office of Student Account...  \n",
      "1                                             Inactive  \n",
      "2                                             Inactive  \n",
      "3                                             Inactive  \n",
      "4    Closed - Referred to Office of Student Account...  \n",
      "..                                                 ...  \n",
      "129                                           Inactive  \n",
      "130                                           Inactive  \n",
      "131  Closed - Referred to Office of Student Account...  \n",
      "132                                           Inactive  \n",
      "133                          Closed - Suspect Arrested  \n",
      "\n",
      "[134 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "# open the Iowa City crime log page\n",
    "url = 'https://safety.uiowa.edu/crime-log#accordion-item-2146-3'\n",
    "browser.get(url)\n",
    "\n",
    "# find the start date and end date input fields\n",
    "start_date_input = browser.find_element(By.ID, 'StartDate')\n",
    "\n",
    "# clear the start date and set it to the beginning of the year\n",
    "start_date_input.clear()\n",
    "start_date_input.send_keys('04-01')\n",
    "\n",
    "# find search button and click\n",
    "search_button = browser.find_element(By.XPATH, '//input[@type=\"button\" and @value=\"Search\"]')\n",
    "\n",
    "browser.execute_script(\"arguments[0].click();\", search_button)\n",
    "\n",
    "# wait for results\n",
    "time.sleep(5)\n",
    "\n",
    "# find the table body\n",
    "table_body = browser.find_element(By.ID, 'table-data')\n",
    "\n",
    "# get all the rows in the table\n",
    "rows = table_body.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# make an empty list to store data\n",
    "crime_data = []\n",
    "\n",
    "# loop through each row and extract the data\n",
    "for row in rows:\n",
    "    columns = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "    # check if row has 6 columns\n",
    "    if len(columns) == 6:\n",
    "        case_number = columns[0].text\n",
    "        classification = columns[1].text\n",
    "        date_time_occurred = columns[2].text\n",
    "        date_time_reported = columns[3].text\n",
    "        location = columns[4].text\n",
    "        disposition = columns[5].text\n",
    "\n",
    "    # append the row data to the list\n",
    "    crime_data.append({\n",
    "        'Case Number': case_number,\n",
    "        'Classification': classification,\n",
    "        'Date/Time Occurred': date_time_occurred,\n",
    "        'Date/Time Reported': date_time_reported,\n",
    "        'Location': location,\n",
    "        'Disposition': disposition\n",
    "    })\n",
    "\n",
    "# close browser\n",
    "browser.quit()\n",
    "\n",
    "# convert into Pandas DF\n",
    "crime_df = pd.DataFrame(crime_data)\n",
    "\n",
    "# convert to CSV file\n",
    "crime_df.to_csv('uiowa_city_crime_data_new.csv', index=False)\n",
    "\n",
    "# display\n",
    "print(crime_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30156a-d964-4e1d-8e3e-efb1ed6d4b21",
   "metadata": {},
   "source": [
    "## Scrape the Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5628166-d33a-4e76-81d6-819a2f48decb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-01\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-02\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-03\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-04\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-05\n",
      "Failed to scrape 2025-04-05: Message: unknown error: cannot determine loading status\n",
      "from unknown error: missing or invalid columnNumber\n",
      "  (Session info: chrome=135.0.7049.115)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6602DEFA5+77893]\n",
      "\tGetHandleVerifier [0x00007FF6602DF000+77984]\n",
      "\t(No symbol) [0x00007FF6600A91BA]\n",
      "\t(No symbol) [0x00007FF66008A43C]\n",
      "\t(No symbol) [0x00007FF660088D0B]\n",
      "\t(No symbol) [0x00007FF66009673E]\n",
      "\t(No symbol) [0x00007FF6600978A0]\n",
      "\t(No symbol) [0x00007FF660096B32]\n",
      "\t(No symbol) [0x00007FF6600965F6]\n",
      "\t(No symbol) [0x00007FF6600962BA]\n",
      "\t(No symbol) [0x00007FF660093F67]\n",
      "\t(No symbol) [0x00007FF66009491F]\n",
      "\t(No symbol) [0x00007FF6600A3D89]\n",
      "\t(No symbol) [0x00007FF6600B9931]\n",
      "\t(No symbol) [0x00007FF6600C08DA]\n",
      "\t(No symbol) [0x00007FF66009508D]\n",
      "\t(No symbol) [0x00007FF6600B9121]\n",
      "\t(No symbol) [0x00007FF66014EF59]\n",
      "\t(No symbol) [0x00007FF660126F03]\n",
      "\t(No symbol) [0x00007FF6600F0328]\n",
      "\t(No symbol) [0x00007FF6600F1093]\n",
      "\tGetHandleVerifier [0x00007FF660597B6D+2931725]\n",
      "\tGetHandleVerifier [0x00007FF660592132+2908626]\n",
      "\tGetHandleVerifier [0x00007FF6605B00F3+3031443]\n",
      "\tGetHandleVerifier [0x00007FF6602F91EA+184970]\n",
      "\tGetHandleVerifier [0x00007FF66030086F+215311]\n",
      "\tGetHandleVerifier [0x00007FF6602E6EC4+110436]\n",
      "\tGetHandleVerifier [0x00007FF6602E7072+110866]\n",
      "\tGetHandleVerifier [0x00007FF6602CD479+5401]\n",
      "\tBaseThreadInitThunk [0x00007FFBEBCFE8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFBEBE914FC+44]\n",
      "\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-06\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-07\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-08\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-09\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-10\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-11\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-12\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-13\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-14\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-15\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-16\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-17\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-18\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-19\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-20\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-21\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-22\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-23\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-24\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-25\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-26\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-27\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-28\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-29\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-04-30\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-01\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-02\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-03\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-04\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-05\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-06\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-07\n",
      "Scraping https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/2025-05-08\n",
      "Scraping completed. Data saved to wunderground_weather.csv\n",
      "            Date      Time Temperature Dew Point Humidity  Wind Wind Speed  \\\n",
      "0     2025-04-01  12:52 AM       34 °F     25 °F     70 %  CALM      0 mph   \n",
      "1     2025-04-01   1:52 AM       34 °F     24 °F     67 %     E      8 mph   \n",
      "2     2025-04-01   2:52 AM       34 °F     25 °F     70 %     E     13 mph   \n",
      "3     2025-04-01   3:52 AM       33 °F     26 °F     75 %     E     13 mph   \n",
      "4     2025-04-01   4:52 AM       33 °F     27 °F     78 %     E     16 mph   \n",
      "...          ...       ...         ...       ...      ...   ...        ...   \n",
      "1105  2025-05-08   8:52 AM       53 °F     39 °F     59 %   ENE     16 mph   \n",
      "1106  2025-05-08   9:52 AM       57 °F     41 °F     55 %    NE     12 mph   \n",
      "1107  2025-05-08  10:52 AM       60 °F     43 °F     53 %   ENE     12 mph   \n",
      "1108  2025-05-08  11:52 AM       62 °F     44 °F     52 %   ENE     14 mph   \n",
      "1109  2025-05-08  12:52 PM       65 °F     46 °F     50 %    NE     12 mph   \n",
      "\n",
      "     Wind Gust  Pressure Precip. Condition  \n",
      "0        0 mph  29.15 in  0.0 in      Fair  \n",
      "1        0 mph  29.13 in  0.0 in      Fair  \n",
      "2        0 mph  29.13 in  0.0 in      Fair  \n",
      "3        0 mph  29.11 in  0.0 in      Fair  \n",
      "4        0 mph  29.11 in  0.0 in      Fair  \n",
      "...        ...       ...     ...       ...  \n",
      "1105     0 mph  29.25 in  0.0 in      Fair  \n",
      "1106     0 mph  29.24 in  0.0 in      Fair  \n",
      "1107    21 mph  29.24 in  0.0 in      Fair  \n",
      "1108    21 mph  29.23 in  0.0 in      Fair  \n",
      "1109     0 mph  29.22 in  0.0 in      Fair  \n",
      "\n",
      "[1110 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "# open the Cedar Rapids Weather History page (Iowa City doesn't have a history option)\n",
    "base_url = 'https://www.wunderground.com/history/daily/us/ia/cedar-rapids/KCID/date/'\n",
    "\n",
    "\n",
    "# Set date range\n",
    "start_date = datetime(2025, 3, 31) + timedelta(days=1)\n",
    "end_date = datetime(2025, 5, 8)\n",
    "current_date = start_date\n",
    "\n",
    "# Data storage\n",
    "weather_data = []\n",
    "\n",
    "while current_date <= end_date:\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    url = base_url + date_str\n",
    "    print(f\"Scraping {url}\")\n",
    "    browser.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for weather table to load\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//table[contains(@class, 'mat-table')]\"))\n",
    "        )\n",
    "\n",
    "        # Extract all table rows\n",
    "        rows = browser.find_elements(By.XPATH, \"//table[contains(@class, 'mat-table')]/tbody/tr\")\n",
    "\n",
    "        for row in rows:\n",
    "            columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            if columns:\n",
    "                time_of_day = columns[0].text.strip()\n",
    "                temp = columns[1].text.strip()\n",
    "                dew_point = columns[2].text.strip()\n",
    "                humidity = columns[3].text.strip()\n",
    "                wind_direction = columns[4].text.strip()\n",
    "                wind_speed = columns[5].text.strip()\n",
    "                wind_gust = columns[6].text.strip()\n",
    "                pressure = columns[7].text.strip()\n",
    "                precip = columns[8].text.strip()\n",
    "                condition = columns[9].text.strip()\n",
    "\n",
    "                weather_data.append([date_str, time_of_day, temp, dew_point, humidity, wind_direction, wind_speed, wind_gust, pressure, precip, condition])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {date_str}: {e}\")\n",
    "\n",
    "    current_date += timedelta(days=1)\n",
    "    time.sleep(2) \n",
    "\n",
    "# close browser\n",
    "browser.quit()\n",
    "\n",
    "# Save to CSV\n",
    "weather_df = pd.DataFrame(weather_data, columns=[\"Date\", \"Time\", \"Temperature\", \"Dew Point\", \"Humidity\", \"Wind\", \"Wind Speed\", \"Wind Gust\", \"Pressure\", \"Precip.\", \"Condition\"])\n",
    "weather_df.to_csv(\"cedarrapids_weather_new.csv\", index=False)\n",
    "print(\"Scraping completed. Data saved to wunderground_weather.csv\")\n",
    "\n",
    "# display\n",
    "print(weather_df)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc868b-67f0-4548-a5ee-a4d037952a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with existing data\n",
    "crime_old = pd.read_csv('uiowa_city_crime_data.csv')\n",
    "crime_new = pd.read_csv('uiowa_city_crime_data_new.csv')\n",
    "weather_old = pd.read_csv('cedarrapids_weather.csv')\n",
    "weather_new = pd.read_csv('cedarrapids_weather_new.csv')\n",
    "\n",
    "# combine\n",
    "crime_combined = pd.concat([crime_old, crime_new], ignore_index=True)\n",
    "weather_combined = pd.concat([weather_old, weather_new], ignore_index=True)\n",
    "\n",
    "# save combined versions\n",
    "crime_combined.to_csv('uiowa_city_crime_data_full.csv', index=False)\n",
    "weather_combined.to_csv('cedarrapids_weather_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d996bf-fad8-4026-826e-260d35adf44b",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bfe0c6-d291-4340-ac81-8598a8d58cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the crime 'Date/Time Occurred' into Date and Time\n",
    "crime_df['Date/Time Reported'] = pd.to_datetime(crime_df['Date/Time Reported'], format = '%m/%d/%Y %H:%M')\n",
    "crime_df['Date'] = crime_df['Date/Time Reported'].dt.date\n",
    "crime_df['Time'] = crime_df['Date/Time Reported'].dt.strftime('%H:%M')\n",
    "\n",
    "display(crime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23fb9f-1893-4a92-8924-2f5ae5b02287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'Date' in weather data to DateTime format\n",
    "weather_df['Date'] = pd.to_datetime(weather_df['Date'], format='%Y-%m-%d')\n",
    "crime_df['Date'] = pd.to_datetime(crime_df['Date'])\n",
    "\n",
    "print(weather_df)\n",
    "print(crime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a671e-58c0-4a2c-a189-b857b4802adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column (time buckets) (this is for future analysis)\n",
    "def assign_time_bucket(time):\n",
    "    if pd.to_datetime(time).hour < 6:\n",
    "        return 'Night'\n",
    "    elif pd.to_datetime(time).hour < 12:\n",
    "        return 'Morning'\n",
    "    elif pd.to_datetime(time).hour < 18:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Evening'\n",
    "\n",
    "# Apply to both datasets\n",
    "merged_df['Time Bucket'] = merged_df['Time'].apply(assign_time_bucket)\n",
    "crime_df['Time Bucket'] = crime_df['Time'].apply(assign_time_bucket)\n",
    "\n",
    "print(weather_df[['Time', 'Time Bucket']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797f724-dc2e-4a57-9928-ea627800c520",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44706b6-e078-4c7b-a07a-118eeb71f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weather data is recorded at specific time intervals (mostly on the hour),\n",
    "so I'm going to match each crime's time to the nearest available weather record\n",
    "for that day\n",
    "'''\n",
    "# convert 'Time' to datetime\n",
    "crime_df['DateTime'] = pd.to_datetime(crime_df['Date'].astype(str) + ' ' + crime_df['Time'])\n",
    "weather_df['DateTime'] = pd.to_datetime(weather_df['Date'].astype(str) + ' ' + weather_df['Time'])\n",
    "\n",
    "# function to find closest available weather time for each crime entry\n",
    "def find_nearest_time(crime_time, weather_times):\n",
    "    return weather_times.iloc[(weather_times - crime_time).abs().argsort()[0]] # find closest time\n",
    "\n",
    "# apply function to assign closest time from weather_df to each crime record\n",
    "crime_df['Nearest Weather Time'] = crime_df['DateTime'].apply(lambda x: find_nearest_time(x, weather_df['DateTime']))\n",
    "\n",
    "# convert back to time format\n",
    "crime_df['Nearest Weather Time'] = crime_df['Nearest Weather Time'].dt.strftime('%H:%M')\n",
    "\n",
    "# format 'Time' in weather_df\n",
    "weather_df['Time'] = weather_df['DateTime'].dt.strftime('%H:%M')\n",
    "\n",
    "# finally merge on date and nearest weather time\n",
    "merged_df = crime_df.merge(weather_df, left_on=['Date', 'Nearest Weather Time'], right_on=['Date','Time'], how = 'left')\n",
    "\n",
    "# display\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d98886-7323-4429-97d9-290280031be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "messed up earlier by applying the time buckets to both datasets, \n",
    "undoing that here\n",
    "'''\n",
    "\n",
    "# drop duplicate columns\n",
    "merged_df = merged_df.drop(columns=['Time_y', 'Time Bucket_y', 'DateTime_y'])\n",
    "\n",
    "# fix the remaining columns' names\n",
    "merged_df.rename(columns={'Time_x': 'Time', 'Time Bucket_x': 'Time Bucket', 'DateTime_x': 'DateTime'}, inplace=True)\n",
    "\n",
    "# display cleaned up dataframe\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053aeb60-b8aa-4bbd-8c3a-c90aa8857701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized there is more cleaning to be done (should've done before merging)\n",
    "merged_df['Temperature'] = merged_df['Temperature'].str.extract('([0-9.]+)').astype(float)\n",
    "merged_df['Dew Point'] = merged_df['Dew Point'].str.extract('([0-9.]+)').astype(float)\n",
    "merged_df['Humidity'] = merged_df['Humidity'].str.extract('([0-9.]+)').astype(float)\n",
    "merged_df['Wind Speed'] = merged_df['Wind Speed'].str.extract('([0-9.]+)').astype(float)\n",
    "merged_df['Wind Gust'] = merged_df['Wind Gust'].str.extract('([0-9.]+)').astype(float)\n",
    "merged_df['Pressure'] = merged_df['Pressure'].str.extract('([0-9.]+)').astype(float)\n",
    "merged_df['Precip.'] = merged_df['Precip.'].str.extract('([0-9.]+)').astype(float)\n",
    "\n",
    "# display the recleaned dataframe\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc3e04-8a31-4729-b740-e557a0894916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the merged dataframe\n",
    "merged_df.to_csv('merged_data_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42d674-0cfa-4ac5-bfd5-7a62c5409a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
